<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>ParallelUtilities · ParallelUtilities.jl</title><link rel="canonical" href="https://jishnub.github.io/ParallelUtilities.jl/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">ParallelUtilities.jl</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>ParallelUtilities</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Performance"><span>Performance</span></a></li><li class="toplevel"><a class="tocitem" href="#Comparison-with-other-parallel-mapreduce-packages"><span>Comparison with other parallel mapreduce packages</span></a></li><li class="toplevel"><a class="tocitem" href="#Known-issues"><span>Known issues</span></a></li></ul></li><li><a class="tocitem" href="pmapreduce/">Mapreduce</a></li><li><a class="tocitem" href="clusterquery/">ClusterQueryUtils</a></li><li><a class="tocitem" href="api/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>ParallelUtilities</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>ParallelUtilities</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/jishnub/ParallelUtilities.jl/blob/master/docs/src/index.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="ParallelUtilities.jl"><a class="docs-heading-anchor" href="#ParallelUtilities.jl">ParallelUtilities.jl</a><a id="ParallelUtilities.jl-1"></a><a class="docs-heading-anchor-permalink" href="#ParallelUtilities.jl" title="Permalink"></a></h1><p>The <code>ParallelUtilities</code> module defines certain functions that are useful in a parallel <code>mapreduce</code> operation, with particular focus on HPC systems. The approach is similar to a <code>@distributed (op) for</code> loop, where the entire section of iterators is split evenly across workers and reduced locally, followed by a global reduction. The operation is not load-balanced at present, and does not support retry on error.</p><h1 id="Performance"><a class="docs-heading-anchor" href="#Performance">Performance</a><a id="Performance-1"></a><a class="docs-heading-anchor-permalink" href="#Performance" title="Permalink"></a></h1><p>The <code>pmapreduce</code>-related functions are expected to be more performant than <code>@distributed</code> for loops. As an example, running the following on a Slurm cluster using 2 nodes with 28 cores on each leads to</p><pre><code class="language-julia">julia&gt; using Distributed

julia&gt; using ParallelUtilities

julia&gt; @everywhere f(x) = ones(10_000, 1_000);

julia&gt; A = @time @distributed (+) for i=1:nworkers()
                f(i)
            end;
 22.637764 seconds (3.35 M allocations: 8.383 GiB, 16.50% gc time, 0.09% compilation time)

julia&gt; B = @time pmapreduce(f, +, 1:nworkers());
  2.170926 seconds (20.47 k allocations: 77.117 MiB)

julia&gt; A == B
true</code></pre><p>The difference increases with the size of data as well as the number of workers. This is because the <code>pmapreduce*</code> functions defined in this package perform local reductions before communicating data across nodes. Note that in this case the same operation may be carried out elementwise to obtain better performance.</p><pre><code class="language-julia">julia&gt; @everywhere elsum(x,y) = x .+= y;

julia&gt; A = @time @distributed (elsum) for i=1:nworkers()
               f(i)
           end;
 20.537353 seconds (4.74 M allocations: 4.688 GiB, 2.56% gc time, 1.26% compilation time)

julia&gt; B = @time pmapreduce(f, elsum, 1:nworkers());
  1.791662 seconds (20.50 k allocations: 77.134 MiB)</code></pre><p>A similar evaluation on 560 cores (20 nodes) takes</p><pre><code class="language-julia">julia&gt; @time for i = 1:10; pmapreduce(f, +, 1:nworkers()); end
145.963834 seconds (2.53 M allocations: 856.693 MiB, 0.12% gc time)

julia&gt; @time for i = 1:10; pmapreduce(f, elsum, 1:nworkers()); end
133.810309 seconds (2.53 M allocations: 856.843 MiB, 0.13% gc time)</code></pre><p>An example of a mapreduce operation involving large arrays (comparable to the memory allocated to each core) evaluated on 56 cores is</p><pre><code class="language-julia">julia&gt; @everywhere f(x) = ones(12_000, 20_000);

julia&gt; @time ParallelUtilities.pmapreduce(f, elsum, 1:nworkers());
 36.824788 seconds (26.40 k allocations: 1.789 GiB, 0.05% gc time)</code></pre><h1 id="Comparison-with-other-parallel-mapreduce-packages"><a class="docs-heading-anchor" href="#Comparison-with-other-parallel-mapreduce-packages">Comparison with other parallel mapreduce packages</a><a id="Comparison-with-other-parallel-mapreduce-packages-1"></a><a class="docs-heading-anchor-permalink" href="#Comparison-with-other-parallel-mapreduce-packages" title="Permalink"></a></h1><p>Other packages that perform parallel mapreduce are <a href="https://github.com/hcarlsso/ParallelMapReduce.jl"><code>ParallelMapReduce</code></a> and <a href="https://github.com/JuliaFolds/Transducers.jl"><code>Transducers</code></a>. The latter provides a <code>foldxd</code> function that performs an associative distributed <code>mapfold</code>. The performances of these functions compared to this package (measured on 1 node with 28 cores) are listed below:</p><pre><code class="language-julia">julia&gt; @everywhere f(x) = ones(10_000, 10_000);

julia&gt; A = @time ParallelUtilities.pmapreduce(f, +, 1:nworkers());
 10.105696 seconds (14.03 k allocations: 763.511 MiB)

julia&gt; B = @time ParallelMapReduce.pmapreduce(f, +, 1:nworkers(), algorithm = :reduction_local);
 30.955381 seconds (231.93 k allocations: 41.200 GiB, 7.63% gc time, 0.23% compilation time)

julia&gt; C = @time Transducers.foldxd(+, 1:nworkers() |&gt; Transducers.Map(f));
 30.154166 seconds (655.40 k allocations: 41.015 GiB, 8.65% gc time, 1.03% compilation time)

julia&gt; A == B == C
true</code></pre><p>Note that at present the performances of the <code>pmapreduce*</code> functions defined in this package are not comparable to equivalent MPI implementations. For example, an MPI mapreduce operation using <a href="https://github.com/jishnub/MPIMapReduce.jl"><code>MPIMapReduce.jl</code></a> computes an inplace sum over <code>10_000 x 10_000</code> matrices on each core in</p><pre><code class="language-julia">3.413968 seconds (3.14 M allocations: 1.675 GiB, 2.99% gc time)</code></pre><p>whereas this package computes it in</p><pre><code class="language-julia">julia&gt; @time ParallelUtilities.pmapreduce(f, elsum, 1:nworkers());
  7.264023 seconds (12.46 k allocations: 763.450 MiB, 1.69% gc time)</code></pre><p>This performance gap might reduce in the future.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The timings have all been measured on Julia 1.6 on an HPC cluster that has nodes with with 2 Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz CPUs (&quot;Broadwell&quot;, 14 cores/socket, 28 cores/node). They are also measured for subsequent runs after an initial precompilation step. The exact evaluation time might also vary depending on the cluster load.</p></div></div><h1 id="Known-issues"><a class="docs-heading-anchor" href="#Known-issues">Known issues</a><a id="Known-issues-1"></a><a class="docs-heading-anchor-permalink" href="#Known-issues" title="Permalink"></a></h1><ol><li><p>This package currently does not implement a specialized <code>mapreduce</code> for arrays, so the behavior might differ for specialized array argument types (eg. <code>DistributedArray</code>s). This might change in the future.</p></li><li><p>This package deals with distributed (multi-core) parallelism, and at this moment it has not been tested alongside multi-threading.</p></li></ol></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="pmapreduce/">Mapreduce »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 4 April 2021 13:11">Sunday 4 April 2021</span>. Using Julia version 1.6.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
